{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrapper to get a name for convolution layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d(nn.Module):\n",
    "    \"\"\"Module allows us to save the name of our layers for cache.\"\"\"\n",
    "    def __init__(self, out_channels, kernel_size):\n",
    "        super(Conv1d, self).__init__()\n",
    "        \n",
    "        self.conv = nn.Sequential()\n",
    "        self.conv.add_module(\n",
    "            f\"conv1d_{str(kernel_size)}_{str(out_channels)}\",\n",
    "            nn.Conv1d(1, out_channels, kernel_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Embedding(nn.Module):\n",
    "    \"\"\"Wrapper for embedding to save names in cache.\"\"\"\n",
    "    def __init__(self, vocab_size, word_dim):\n",
    "        super(Embedding, self).__init__()\n",
    "        \n",
    "        self.emb = nn.Sequential()\n",
    "        self.emb.add_module(\n",
    "            f\"embedding_{str(vocab_size)}_{str(word_dim)}\",\n",
    "            nn.Embedding(vocab_size + 2, word_dim, padding_idx=0)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.emb(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compose multiple convolution layers together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, hparams):\n",
    "        super(CNN, self).__init__()\n",
    "        self.hp = hparams\n",
    "        self.embedding = Embedding(hparams.vocab_size, hparams.word_dim)\n",
    "        self.conv1 = Conv1d(hparams.n_filters1, hparams.kernel1)\n",
    "        self.conv2 = Conv1d(hparams.n_filters2, hparams.kernel2)\n",
    "        self.conv3 = Conv1d(hparams.n_filters3, hparams.kernel3)\n",
    "        self.fc = nn.Linear(self._sum_filters(), 10)\n",
    "        \n",
    "    def _sum_filters(self):\n",
    "        return self.hp.n_filters1 + self.hp.n_filters2 + self.hp.n_filters3\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x).view(-1, 1, self.hp.word_dim * self.hp.max_sent_len)\n",
    "        \n",
    "        conv_results = []\n",
    "        conv_results.append(nn.ReLU(self.conv1(x)).view(-1, self.hp.n_filters1))\n",
    "        conv_results.append(nn.ReLU(self.conv2(x)).view(-1, self.hp.n_filters2))\n",
    "        conv_results.append(nn.ReLU(self.conv2(x)).view(-1, self.hp.n_filters3))\n",
    "        x = torch.cat(conv_results, 1)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hyperparameters:\n",
    "    kernel1 = 3\n",
    "    kernel2 = 4\n",
    "    kernel3 = 5\n",
    "    n_filters1 = 300\n",
    "    n_filters2 = 300\n",
    "    n_filters3 = 300\n",
    "    vocab_size = 3000\n",
    "    word_dim = 100\n",
    "    max_sent_len = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = Hyperparameters()\n",
    "hparams.n_filters1 = 4\n",
    "model = CNN(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "save = torch.load('model')\n",
    "model = CNN(hparams)\n",
    "model.load_state_dict(save, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding.emb.embedding_3000_100.weight\n",
      "conv1.conv.conv1d_3_4.weight\n",
      "conv1.conv.conv1d_3_4.bias\n",
      "conv2.conv.conv1d_4_300.weight\n",
      "conv2.conv.conv1d_4_300.bias\n",
      "conv3.conv.conv1d_5_300.weight\n",
      "conv3.conv.conv1d_5_300.bias\n",
      "fc.weight\n",
      "fc.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new(hyperparameters=None, savefile=None):\n",
    "    \"\"\"Create new MTCNN model.\"\"\"\n",
    "    if hyperparameters:\n",
    "        hparams = hyperparameters\n",
    "    else:\n",
    "        hparams = Hyperparameters()\n",
    "        \n",
    "    model = CNN(hparams)\n",
    "        \n",
    "    if savefile:\n",
    "        model.load_state_dict(savefile, strict=False)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperspace_update = {\n",
    "    'kernel1': 1,\n",
    "    'kernel2': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams.kernel1 = hyperspace_update['kernel1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (embedding): Embedding(\n",
       "    (emb): Sequential(\n",
       "      (embedding_3000_100): Embedding(3002, 100, padding_idx=0)\n",
       "    )\n",
       "  )\n",
       "  (conv1): Conv1d(\n",
       "    (conv): Sequential(\n",
       "      (conv1d_3_300): Conv1d(1, 300, kernel_size=(3,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       "  (conv2): Conv1d(\n",
       "    (conv): Sequential(\n",
       "      (conv1d_4_300): Conv1d(1, 300, kernel_size=(4,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       "  (conv3): Conv1d(\n",
       "    (conv): Sequential(\n",
       "      (conv1d_5_300): Conv1d(1, 300, kernel_size=(5,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=900, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.LongTensor(100).random_(0, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[-1, 1, 30000]' is invalid for input of size 10000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-183-bd0200007a4a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/src/checkout/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-140-f60ac14220b3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_dim\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_sent_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mconv_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[-1, 1, 30000]' is invalid for input of size 10000"
     ]
    }
   ],
   "source": [
    "model(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
